{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detr_tf.data.coco import load_coco_dataset\n",
    "from detr_tf.networks.detr import get_detr_model\n",
    "from detr_tf.optimizers import setup_optimizers\n",
    "from detr_tf.optimizers import gather_gradient, aggregate_grad_and_apply\n",
    "from detr_tf.logger.training_logging import train_log, valid_log\n",
    "from detr_tf.loss.loss import get_losses\n",
    "from detr_tf.training_config import TrainingConfig, training_config_parser\n",
    "from detr_tf import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.train_backbone = tf.Variable(True)\n",
    "config.train_transformers = tf.Variable(True)\n",
    "config.train_nlayers = tf.Variable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights from weights/detr/detr.ckpt\n",
      "Model: \"detr_finetuning\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "detr (Functional)               (6, None, 100, 256)  41475712    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bbox_embed_0 (Linear)           (6, None, 100, 256)  65792       detr[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (6, None, 100, 256)  0           bbox_embed_0[0][0]               \n",
      "                                                                 bbox_embed_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bbox_embed_1 (Linear)           (6, None, 100, 256)  65792       re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bbox_embed_2 (Linear)           (6, None, 100, 4)    1028        re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sigmoid (TensorFlow [(6, None, 100, 4)]  0           bbox_embed_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "class_embed (Linear)            (6, None, 100, 92)   23644       detr[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 100, 4)]     0           tf_op_layer_Sigmoid[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [(None, 100, 92)]    0           class_embed[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 100, 4)]     0           tf_op_layer_Sigmoid[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [(None, 100, 92)]    0           class_embed[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 100, 4)]     0           tf_op_layer_Sigmoid[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [(None, 100, 92)]    0           class_embed[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 100, 4)]     0           tf_op_layer_Sigmoid[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [(None, 100, 92)]    0           class_embed[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 100, 4)]     0           tf_op_layer_Sigmoid[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [(None, 100, 92)]    0           class_embed[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 100, 4)]     0           tf_op_layer_Sigmoid[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 100, 92)]    0           class_embed[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 41,631,968\n",
      "Trainable params: 41,578,848\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "detr = get_detr_model(config, include_top=True, tf_backbone=True, weights=\"detr\")\n",
    "detr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'plot_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-96f345752780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'plot_model'"
     ]
    }
   ],
   "source": [
    "detr.plot_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dt, coco_class_names = load_coco_dataset(\n",
    "        config, config.batch_size, augmentation=True, img_dir=\"train2017\", \n",
    "        ann_file=\"annotations_trainval2017/annotations/instances_train2017.json\")\n",
    "\n",
    "valid_dt, _ = load_coco_dataset(\n",
    "        config, 1, augmentation=False, img_dir=\"val2017\", \n",
    "        ann_file=\"annotations_trainval2017/annotations/instances_val2017.json\")\n",
    "\n",
    "    # Train the backbone and the transformers\n",
    "    # Check the training_config file for the other hyperparameters\n",
    "config.train_backbone = True\n",
    "config.train_transformers = True\n",
    "\n",
    "    # Setup the optimziers and the trainable variables\n",
    "optimzers = setup_optimizers(detr, config)\n",
    "\n",
    "    # Run the training for 100 epochs\n",
    "for epoch_nb in range(1):\n",
    "#     training.eval(detr, valid_dt, config, coco_class_names, evaluation_step=200)\n",
    "    training.fit(detr, train_dt, optimzers, config, epoch_nb, coco_class_names, valid_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_nb in range(1):\n",
    "    training.eval(detr, valid_dt, config, coco_class_names, evaluation_step=200)\n",
    "#     training.fit(detr, train_dt, optimzers, config, epoch_nb, coco_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from detr_tf.inference import get_model_inference\n",
    "from detr_tf.data.coco import load_coco_dataset\n",
    "from detr_tf.loss.compute_map import cal_map, calc_map, APDataObject\n",
    "from detr_tf.networks.detr import get_detr_model\n",
    "from detr_tf.bbox import xcycwh_to_xy_min_xy_max, xcycwh_to_yx_min_yx_max\n",
    "from detr_tf.inference import numpy_bbox_to_image\n",
    "from detr_tf.training_config import TrainingConfig, training_config_parser\n",
    "def build_model(config):\n",
    "    \"\"\" Build the model with the pretrained weights. In this example\n",
    "    we do not add new layers since the pretrained model is already trained on coco.\n",
    "    See examples/finetuning_voc.py to add new layers.\n",
    "    \"\"\"\n",
    "    # Load the pretrained model\n",
    "    detr = get_detr_model(config, include_top=True, weights=\"detr\")\n",
    "    detr.summary()\n",
    "    return detr\n",
    "\n",
    "\n",
    "def eval_model(model, config, class_names, valid_dt):\n",
    "    \"\"\" Run evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    iou_thresholds = [x / 100. for x in range(50, 100, 5)]\n",
    "    ap_data = {\n",
    "        'box' : [[APDataObject() for _ in class_names] for _ in iou_thresholds],\n",
    "        'mask': [[APDataObject() for _ in class_names] for _ in iou_thresholds]\n",
    "    }\n",
    "    it = 0\n",
    "\n",
    "    for images, target_bbox, target_class in valid_dt:\n",
    "        # Forward pass\n",
    "        m_outputs = model(images)\n",
    "        # Run predictions\n",
    "        p_bbox, p_labels, p_scores = get_model_inference(m_outputs, config.background_class, bbox_format=\"yxyx\")\n",
    "        # Remove padding\n",
    "        t_bbox, t_class = target_bbox[0], target_class[0]\n",
    "        size = tf.cast(t_bbox[0][0], tf.int32)\n",
    "        t_bbox = tf.slice(t_bbox, [1, 0], [size, 4])\n",
    "        t_bbox = xcycwh_to_yx_min_yx_max(t_bbox)\n",
    "        t_class = tf.slice(t_class, [1, 0], [size, -1])\n",
    "        t_class = tf.squeeze(t_class, axis=-1)\n",
    "        # Compute map\n",
    "        cal_map(p_bbox, p_labels, p_scores,  np.zeros((138, 138, len(p_bbox))), np.array(t_bbox), np.array(t_class), np.zeros((138, 138, len(t_bbox))), ap_data, iou_thresholds)\n",
    "        print(f\"Computing map.....{it}\", end=\"\\r\")\n",
    "        it += 1\n",
    "        #if it > 10:\n",
    "        #    break\n",
    "\n",
    "    # Compute the mAp over all thresholds\n",
    "    calc_map(ap_data, iou_thresholds, class_names, print_result=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.74s)\n",
      "creating index...\n",
      "index created!\n",
      "Computing map.....12\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dhruv/detr-tensorflow-main/detr-tensorflow-main/detr_tf/loss/compute_map.py:101: RuntimeWarning: invalid value encountered in true_divide\n",
      "  overlaps = intersections / union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing map.....4540\n",
      "       |  all  |  .50  |  .55  |  .60  |  .65  |  .70  |  .75  |  .80  |  .85  |  .90  |  .95  |\n",
      "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "   box |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |\n",
      "  mask |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |  0.00 |\n",
      "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = TrainingConfig()\n",
    "\n",
    "    # Load the model with the new layers to finetune\n",
    "\n",
    "valid_dt, class_names = load_coco_dataset(\n",
    "        config, 1, augmentation=False, img_dir=\"val2017\", \n",
    "        ann_file=\"annotations_trainval2017/annotations/instances_val2017.json\")\n",
    "\n",
    "    # Run training\n",
    "eval_model(detr, config, class_names, valid_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (7, 2, 2)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 2, 2)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: weights/detr/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-73aa8d4cbae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# requires some data for calibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_saved_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, calibration_input_fn)\u001b[0m\n\u001b[1;32m   1082\u001b[0m                        \"calibration is not needed\")\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m     self._saved_model = load.load(self._input_saved_model_dir,\n\u001b[0m\u001b[1;32m   1085\u001b[0m                                   self._input_saved_model_tags)\n\u001b[1;32m   1086\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_saved_model_signature_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \"\"\"\n\u001b[0;32m--> 603\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, options, loader_cls)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m--> 614\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \"\"\"\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   debug_info_path = os.path.join(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: weights/detr/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "import tensorflow as tf\n",
    "conversion_params = trt.TrtConversionParams(\n",
    "    precision_mode=trt.TrtPrecisionMode.INT8)\n",
    "\n",
    "converter = tf.experimental.tensorrt.Converter(\n",
    "    input_saved_model_dir='weights/detr')\n",
    "\n",
    "# requires some data for calibration\n",
    "converter.convert()\n",
    "converter.save(output_saved_model_dir)\n",
    "\n",
    "# Optionally build TensorRT engines before deployment.\n",
    "# Note that this is GPU specific, and as a rule of thumb we recommend building at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
